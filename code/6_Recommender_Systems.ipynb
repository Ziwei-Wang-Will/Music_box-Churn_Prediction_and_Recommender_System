{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music_Box - Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main tasks\n",
    "\n",
    "1. Clean data and create utility matrix  \n",
    "2. Build Recommenders and insights  \n",
    "    - 2.1 Popularity-based recommender  \n",
    "    - 2.2 Neighborhood-based Approach Collaborative Filtering Recommender  \n",
    "        - 2.2.1 Item-Item similarity recommender  \n",
    "    - 2.3 Matrix Factorization Approach Collaborative Filtering Recommender  \n",
    "        - 2.3.1 NMF  \n",
    "        - 2.3.2 UVD \n",
    "    - 2.4 Specific recommendation results comparison and insights  \n",
    "    - 2.5 Next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from time import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>song_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10199495</td>\n",
       "      <td>22820742</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104213634</td>\n",
       "      <td>6096002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104992781</td>\n",
       "      <td>127709</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104992781</td>\n",
       "      <td>708290</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10607827</td>\n",
       "      <td>22872742</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid   song_id  rating\n",
       "0   10199495  22820742     2.0\n",
       "1  104213634   6096002     1.0\n",
       "2  104992781    127709     4.0\n",
       "3  104992781    708290     4.0\n",
       "4   10607827  22872742     4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean data and create utility matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relevant columns in the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2539015, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get song_id, uid, rating for recommender\n",
    "\n",
    "df_recommender = df[['song_id', 'uid', 'rating']]\n",
    "df_recommender.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To reduce compute time, we apply downsample on song_id level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id list\n",
    "df_user_list = np.array(df_recommender['uid'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users: 56694\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of users:\",len(df_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample ids\n",
    "np.random.seed = 1\n",
    "down_sample_ratio = 0.05\n",
    "id_subset = pd.DataFrame(df_user_list[np.random.random(df_user_list.shape)<down_sample_ratio])\n",
    "id_subset.columns = ['uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of users after down sample: 2845\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of users after down sample:\",len(id_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130791, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retain only random seleted samples\n",
    "df_recommender_down_sample = pd.merge(id_subset, df_recommender, on = 'uid', how = 'left')\n",
    "df_recommender_down_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many users that haven't play many songs, exclude these users from the utility matrix, retain only users play more than five songs.\n",
    "#### For the removed or new users, we can recommend popular songs at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 'uid' play more than 5 songs\n",
    "df_user = df_recommender_down_sample['uid'].value_counts()\n",
    "df_user = df_user[df_user >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2125, 129407)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.count(), df_user.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>song_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167657491</td>\n",
       "      <td>1745818</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167657491</td>\n",
       "      <td>23537652</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid   song_id  rating\n",
       "0  167657491   1745818     1.0\n",
       "1  167657491  23537652     1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter users play more than 5 songs and set user_id as index\n",
    "df_recommender_cleaned = df_recommender_down_sample.set_index('uid').ix[df_user.index].reset_index()\n",
    "df_recommender_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129407, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommender_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract the unique list of user_id and song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_number</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>167657491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>169029614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_number        uid\n",
       "0            0  167657491\n",
       "1            1  169029614"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_list = pd.DataFrame(df_recommender_cleaned['uid'].unique())\n",
    "user_id_list = user_id_list.reset_index()\n",
    "# Rename the columns \n",
    "user_id_list.columns = ['user_number', 'uid']\n",
    "user_id_list.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_number</th>\n",
       "      <th>song_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1745818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>23537652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_number   song_id\n",
       "0            0   1745818\n",
       "1            1  23537652"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_id_list = pd.DataFrame(df_recommender_cleaned['song_id'].unique())\n",
    "song_id_list = song_id_list.reset_index()\n",
    "# Rename the columns \n",
    "song_id_list.columns = ['song_number', 'song_id']\n",
    "song_id_list.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>song_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>user_number</th>\n",
       "      <th>song_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167657491</td>\n",
       "      <td>1745818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167657491</td>\n",
       "      <td>23537652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid   song_id  rating  user_number  song_number\n",
       "0  167657491   1745818     1.0            0            0\n",
       "1  167657491  23537652     1.0            0            1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge \"df_recommender_cleaned\", \"user_id_list\" and \"song_id_list\"\n",
    "df_recommender_cleaned = pd.merge(df_recommender_cleaned, user_id_list, on = 'uid', how = 'left')\n",
    "df_recommender_cleaned = pd.merge(df_recommender_cleaned, song_id_list, on = 'song_id', how = 'left')\n",
    "\n",
    "df_recommender_cleaned.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create utility matrix from records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### convert to sparse matrix using scipy.sparse.lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2125x53728 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in LInked List format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_user_id = df_recommender_cleaned.user_number.max()\n",
    "highest_song_id = df_recommender_cleaned.song_number.max()\n",
    "ratings_mat = sparse.lil_matrix((highest_user_id + 1, highest_song_id + 1))\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter in utility_mat with rating\n",
    "for _, row in df_recommender_cleaned.iterrows():\n",
    "    ratings_mat[row.user_number, row.song_number] = row.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2125x53728 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 129407 stored elements in LInked List format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_mat = ratings_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Recommenders and insights\n",
    "\n",
    "- 2.1 Popularity-based recommender  \n",
    "- 2.2 Neighborhood-based Approach Collaborative Filtering Recommender  \n",
    "    - 2.2.1 Item-Item similarity recommender  \n",
    "- 2.3 Matrix Factorization Approach Collaborative Filtering Recommender  \n",
    "    - 2.3.1 NMF  \n",
    "    - 2.3.2 UVD \n",
    "- 2.4 Specific recommendation results comparison and insights  \n",
    "- 2.5 Next step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Popularity-based recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every new user or user played less than five songs, we build a Popularity-based recommender to recommend most popular songs at first.\n",
    "### We define 'popular' as songs with most played records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count by song_id and rank to find the mose popular songs\n",
    "n = 10\n",
    "\n",
    "# 'song_id' for the n mostly played songs\n",
    "Popularity_based_top_10_song_id = df['song_id'].value_counts()[:n].index.tolist()\n",
    "# corresponding 'song_number' for n mostly played songs 'song_id' \n",
    "Popularity_based_top_10 = []\n",
    "for i in Popularity_based_top_10_song_id:\n",
    "    Popularity_based_top_10.append((song_id_list[song_id_list['song_id'] == i]['song_number'].values)[0])\n",
    "\n",
    "# for top 100 recommended songs\n",
    "Popularity_based_top_100_song_id = df['song_id'].value_counts()[:(n * 10)].index.tolist()\n",
    "# corresponding 'song_number' for n mostly played songs 'song_id' \n",
    "Popularity_based_top_100 = []\n",
    "for i in Popularity_based_top_100_song_id:\n",
    "    Popularity_based_top_100.append((song_id_list[song_id_list['song_id'] == i]['song_number'].values)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity-based recommender recommends top 10 songs: \n",
      " [2088, 5163, 6116, 5872, 6125, 15662, 5785, 6059, 5550, 1454]\n"
     ]
    }
   ],
   "source": [
    "print('Popularity-based recommender recommends top ' + str(n) +' songs:', '\\n', str(Popularity_based_top_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Neighborhood-based Approach Collaborative Filtering Recommender\n",
    "### 2.2.1 Item-Item similarity recommender "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For user played more than five songs, we try Neighborhood-based approach to build an Item-Item similarity recommender here, given a user_id and recommend 10 songs which have the largest similarities with songs the user had played before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate item-item similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-Item Similarity Matrix\n",
    "item_sim_mat = cosine_similarity(utility_mat.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_to_most_sim_indexes = np.argsort(item_sim_mat, axis=1)\n",
    "\n",
    "# Neighborhoods\n",
    "neighborhood_size = 75\n",
    "neighborhoods = least_to_most_sim_indexes[:, -neighborhood_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53728, 75)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make rating prediction on a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a lucky user\n",
    "user_id = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Execution time: 34.418968 seconds\n"
     ]
    }
   ],
   "source": [
    "n_users = utility_mat.shape[0]\n",
    "n_items = utility_mat.shape[1]\n",
    "\n",
    "start_time = time()\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "# Just initializing so we have somewhere to put rating preds\n",
    "out = np.zeros(n_items)\n",
    "for item_to_rate in range(n_items):\n",
    "    relevant_items = np.intersect1d(neighborhoods[item_to_rate],\n",
    "                                    items_rated_by_this_user,\n",
    "                                    assume_unique=True)  # assume_unique speeds up intersection op\n",
    "    out[item_to_rate] = ratings_mat[user_id, relevant_items] * \\\n",
    "        item_sim_mat[item_to_rate, relevant_items] / \\\n",
    "        item_sim_mat[item_to_rate, relevant_items].sum()\n",
    "\n",
    "\n",
    "pred_ratings = np.nan_to_num(out)\n",
    "print(pred_ratings)\n",
    "print(\"Execution time: %f seconds\" % (time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53728,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to get final recommendations for a user: user_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-Item similarity recommender recommends top 10 songs: \n",
      " [47185, 41924, 36516, 36517, 36518, 46249, 46248, 46247, 46246, 46245]\n"
     ]
    }
   ],
   "source": [
    "# Recommend n songs\n",
    "n = 10\n",
    "\n",
    "# Get item indexes sorted by predicted rating\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "# Find items that have been rated by user\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "# We want to exclude the items that have been rated by user\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "Item_Item_top_10 = unrated_items_by_pred_rating[:n]\n",
    "Item_Item_top_100 = unrated_items_by_pred_rating[:(n * 10)]\n",
    "print('Item-Item similarity recommender recommends top ' + str(n) +' songs:', '\\n', str(Item_Item_top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_abs_err: 0.9656061865673606\n"
     ]
    }
   ],
   "source": [
    "### check errors\n",
    "# truth\n",
    "ratings_true = ratings_mat[user_id, items_rated_by_this_user].todense()\n",
    "# prediction\n",
    "ratings_pred = pred_ratings[items_rated_by_this_user]\n",
    "# print(list(zip(np.array(ratings_true).squeeze(),ratings_pred)))\n",
    "err_one_user = ratings_true-ratings_pred\n",
    "# print(err_one_user)\n",
    "print(\"average_abs_err:\", abs(err_one_user).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we will try Matrix Factorization approach to build recommender, because matrix factorization models always perform better than neighborhood models in collaborative filtering. The reason as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is when we factorize a ‘m*n’ matrix into two ‘m*k’ and ‘k*n’ matrices we are reducing our \"n\"items to \"k\"factors, which means that instead than having our 50000 songs, we now have 500 factors where each factor is a linear combination of songs.  \n",
    "\n",
    "\n",
    "The key is that recommending based on factors is more robust than just using movie similarities, maybe a user hasn’t played ‘stay’ but the user might have player other songs that are related to ‘stay’ via some latent factors and those can be used.  \n",
    "\n",
    "\n",
    "The factors are called latent because they are there in our data but are not really discovered until we run the reduced rank matrix factorization, then the factors emerge and hence the \"latency\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Matrix Factorization Approach Collaborative Filtering Recommender\n",
    "\n",
    "### Here we will compare two Matrix Factorization approaches: sklearn NMF and sklearn UVD.\n",
    "\n",
    "### 2.3.1 NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521.7083413877025\n",
      "(2125, 700) (700, 53728)\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "def fit_nmf(M,k):\n",
    "    nmf = NMF(n_components=k)\n",
    "    nmf.fit(M)\n",
    "    W = nmf.transform(M);\n",
    "    H = nmf.components_;\n",
    "    err = nmf.reconstruction_err_\n",
    "    return W,H,err\n",
    "\n",
    "# decompose\n",
    "W,H,err = fit_nmf(ratings_mat,700)\n",
    "print(err)\n",
    "print(W.shape,H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.3494214143459113\n",
      "average_abs_err:  0.6121270441200024\n"
     ]
    }
   ],
   "source": [
    "# calculate model performance\n",
    "\n",
    "# reconstruct\n",
    "ratings_mat_fitted = W.dot(H)\n",
    "errs = np.array((ratings_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array((ratings_mat.todense()).flatten()).squeeze()>0\n",
    "\n",
    "rmse = math.sqrt(np.mean(errs[mask]**2))\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"average_abs_err: \", average_abs_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RMSE of NMF is 1.3494, and the average absolute error is 0.6121, the performance is acceptable.\n",
    "#### Next we will try to get recommendations for a user: user_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF recommender recommends top 10 songs: \n",
      " [51347, 51348, 41708, 1170, 11460, 1666, 7873, 7144, 10250, 6837]\n"
     ]
    }
   ],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 100\n",
    "n = 10\n",
    "\n",
    "pred_ratings = ratings_mat_fitted[user_id,:]\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "NMF_top_10 = unrated_items_by_pred_rating[:n]\n",
    "NMF_top_100 = unrated_items_by_pred_rating[:(n * 10)]\n",
    "print('NMF recommender recommends top ' + str(n) +' songs:', '\\n', str(NMF_top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_abs_err: 0.01373477484767313\n"
     ]
    }
   ],
   "source": [
    "### check errors\n",
    "# truth\n",
    "ratings_true = ratings_mat[user_id, items_rated_by_this_user].todense()\n",
    "# prediction\n",
    "ratings_pred = pred_ratings[items_rated_by_this_user]\n",
    "# print(list(zip(np.array(ratings_true).squeeze(),ratings_pred)))\n",
    "err_one_user = ratings_true-ratings_pred\n",
    "# print(err_one_user)\n",
    "print(\"average_abs_err:\", abs(err_one_user).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same as what we discussed above, the average absolute error of NMF for this specific user is better than 0.9656 of Item-Item similarity recommender.\n",
    "#### Next we will try UVD to verify whether it performs better than NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 UVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125, 700) (700, 53728)\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def fit_uvd(M,k):\n",
    "    # use TruncatedSVD to realize UVD\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=7, random_state=0)\n",
    "    svd.fit(M)\n",
    "\n",
    "    V = svd.components_\n",
    "    U = svd.transform(M) # effectively, it's doing: U = M.dot(V.T)\n",
    "    # we can ignore svd.singular_values_ for our purpose\n",
    "    \n",
    "    return U,V, svd\n",
    "\n",
    "# decompose\n",
    "U,V,svd = fit_uvd(ratings_mat,700)\n",
    "\n",
    "print(U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.1729298833883894\n",
      "average_abs_err:  0.5569352701973516\n"
     ]
    }
   ],
   "source": [
    "# calculate model performance\n",
    "\n",
    "# reconstruct\n",
    "ratings_mat_fitted = U.dot(V) # U*V\n",
    "\n",
    "# recall: U = M.dot(V.T), then this is M.dot(V.T).dot(V)\n",
    "# original M is transformed to new space, then transformed back\n",
    "# this is another way to understand it!\n",
    "\n",
    "# calculate errs\n",
    "errs = np.array((ratings_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array((ratings_mat.todense()).flatten()).squeeze()>0\n",
    "\n",
    "rmse = math.sqrt(np.mean(errs[mask]**2))\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"average_abs_err: \", average_abs_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RMSE of UVD is 1.1729 and the average absolute error is 0.5569, which are better than scores of NMF(1.3494 and 0.6121). \n",
    "#### UVD performs better because it has larger degree of freedom than NMF, to be specific, NMF is a specialization of UVD, all values of V, W, and H in NMF must be non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will try to get recommendations for a user: user_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UVD recommender recommends top 10 songs: \n",
      " [10718, 6837, 4440, 10605, 21281, 1170, 21562, 51347, 51348, 6422]\n"
     ]
    }
   ],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 100\n",
    "n = 10\n",
    "\n",
    "pred_ratings = ratings_mat_fitted[user_id,:]\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "TruncatedSVD_top_10 = unrated_items_by_pred_rating[:n]\n",
    "TruncatedSVD_top_100 = unrated_items_by_pred_rating[:(n * 10)]\n",
    "print('UVD recommender recommends top ' + str(n) +' songs:', '\\n', str(TruncatedSVD_top_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_abs_err: 0.03912211740335811\n"
     ]
    }
   ],
   "source": [
    "### check errors\n",
    "# truth\n",
    "ratings_true = ratings_mat[user_id, items_rated_by_this_user].todense()\n",
    "# prediction\n",
    "ratings_pred = pred_ratings[items_rated_by_this_user]\n",
    "# print(list(zip(np.array(ratings_true).squeeze(),ratings_pred)))\n",
    "err_one_user = ratings_true-ratings_pred\n",
    "# print(err_one_user)\n",
    "print(\"average_abs_err:\", abs(err_one_user).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average absolute error of UVD is 0.0391, which is very close to 0.0137 of NMF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Specific recommendation results comparison and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we compare the recommendation results for 'user with user_number = 100' generated by the four models above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generate the overlap tabel of the top_10 results given by the four models for 'user with user_number = 100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlap of the top 10 recommendation generated by these four models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_same_recommended_songs_in_top_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_Item-Item</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_NMF</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_UVD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item-Item_with_NMF</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item-Item_with_UVD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_with_UVD</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_Item-Item_with_NMF_with_UVD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   number_of_same_recommended_songs_in_top_10\n",
       "Popularity-based_with_Item-Item                                                             0\n",
       "Popularity-based_with_NMF                                                                   0\n",
       "Popularity-based_with_UVD                                                                   0\n",
       "Item-Item_with_NMF                                                                          0\n",
       "Item-Item_with_UVD                                                                          0\n",
       "NMF_with_UVD                                                                                4\n",
       "Popularity-based_with_Item-Item_with_NMF_with_UVD                                           0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_overlap = pd.DataFrame([len(np.intersect1d(Popularity_based_top_10, Item_Item_top_10)),\n",
    "                                   len(np.intersect1d(Popularity_based_top_10, TruncatedSVD_top_10)),\n",
    "                                   len(np.intersect1d(Popularity_based_top_10, NMF_top_10)),\n",
    "                                   len(np.intersect1d(Item_Item_top_10, NMF_top_10)),\n",
    "                                   len(np.intersect1d(Item_Item_top_10, TruncatedSVD_top_10)),\n",
    "                                   len(np.intersect1d(NMF_top_10, TruncatedSVD_top_10)),\n",
    "                                   len(np.intersect1d(np.intersect1d(np.intersect1d(Popularity_based_top_10, Item_Item_top_10), NMF_top_10), TruncatedSVD_top_10))],\n",
    "                                 index = ['Popularity-based_with_Item-Item',\n",
    "                                           'Popularity-based_with_NMF',\n",
    "                                           'Popularity-based_with_UVD',\n",
    "                                           'Item-Item_with_NMF',\n",
    "                                           'Item-Item_with_UVD',\n",
    "                                           'NMF_with_UVD',\n",
    "                                           'Popularity-based_with_Item-Item_with_NMF_with_UVD'],\n",
    "                                 columns = ['number_of_same_recommended_songs_in_top_10'])\n",
    "print('The overlap of the top 10 recommendation generated by these four models') \n",
    "top10_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generate the overlap tabel of the top_100 results given by the four models for 'user with user_number = 100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overlap of the top 100 recommendation generated by these four models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_same_recommended_songs_in_top_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_Item-Item</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_NMF</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_UVD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item-Item_with_NMF</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item-Item_with_UVD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_with_UVD</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Popularity-based_with_Item-Item_with_NMF_with_UVD</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   number_of_same_recommended_songs_in_top_100\n",
       "Popularity-based_with_Item-Item                                                              0\n",
       "Popularity-based_with_NMF                                                                    3\n",
       "Popularity-based_with_UVD                                                                    1\n",
       "Item-Item_with_NMF                                                                           0\n",
       "Item-Item_with_UVD                                                                           0\n",
       "NMF_with_UVD                                                                                66\n",
       "Popularity-based_with_Item-Item_with_NMF_with_UVD                                            0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100_overlap = pd.DataFrame([len(np.intersect1d(Popularity_based_top_100, Item_Item_top_100)),\n",
    "                                   len(np.intersect1d(Popularity_based_top_100, TruncatedSVD_top_100)),\n",
    "                                   len(np.intersect1d(Popularity_based_top_100, NMF_top_100)),\n",
    "                                   len(np.intersect1d(Item_Item_top_100, NMF_top_100)),\n",
    "                                   len(np.intersect1d(Item_Item_top_100, TruncatedSVD_top_100)),\n",
    "                                   len(np.intersect1d(NMF_top_100, TruncatedSVD_top_100)),\n",
    "                                   len(np.intersect1d(np.intersect1d(np.intersect1d(Popularity_based_top_100, Item_Item_top_100), NMF_top_100), TruncatedSVD_top_100))],\n",
    "                                 index = ['Popularity-based_with_Item-Item',\n",
    "                                           'Popularity-based_with_NMF',\n",
    "                                           'Popularity-based_with_UVD',\n",
    "                                           'Item-Item_with_NMF',\n",
    "                                           'Item-Item_with_UVD',\n",
    "                                           'NMF_with_UVD',\n",
    "                                           'Popularity-based_with_Item-Item_with_NMF_with_UVD'],\n",
    "                                 columns = ['number_of_same_recommended_songs_in_top_100'])\n",
    "print('The overlap of the top 100 recommendation generated by these four models') \n",
    "top100_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the intersets tables above, we notice that: \n",
    "\n",
    "1. The recommended songs given by Popularity-based, Neighborhood-based approach and Matrix Factorization approach models are very different from each other, have no overlap in top 10 and only 3 overlaps in top 100 recommended songs. \n",
    "\n",
    "2. While the recommended songs given by NMF and UVD have 4 overlaps in top 10 and 66 overlaps in top 100 recommended songs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlcusion:\n",
    "\n",
    "1. For new user or user played less than five songs, we can recommend most popular songs at first generated by our Popularity-based recommender.  \n",
    "\n",
    "2. For user played more than five songs:  \n",
    "2.1 Given the performances of NMF and UVD are comparable, we can have the overlap of commendation results generated by these two models as the final recommendation.  \n",
    "2.2 As the results generated by Popularity-based, Neighborhood-based Approach and Matrix Factorization Approach models are totally different, we can allocate different weights to these models to construct the final recommendation.   \n",
    "Like 0.2 for Popularity-based, 0.2 for Neighborhood-based, 0.6 for overlap of NMF and UVD.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Besides the insights mentioned above, I think there are aspects we can further dive deep, like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we have huge amounts of users, we can try to perform clustering to all users, cluster users with high similarities into the same cluster, which allows us to perform different recommendation algorithm to different clusters, more efficient and more targeted.\n",
    "\n",
    "2. Develop 'dislike' feature which allow users to flag songs they don't like, so that our recommender will not recommend the disliked songs again, on the other hand, our recommender can avoid recommending songs with high similarities with disliked songs.\n",
    "\n",
    "3. Our recommendation system should also consider the style of the song, such as recommending rock or pop music in working hours, recommending light music or antiques in evening time, etc."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
